# (Remote) Data Scientist - Rackspace Private Cloud

## General Rackspace Data Scientist Job Description

N.B., See the [Ops Fabric Data Scientist Focus section](#ops-fabric-data-scientist-focus) for a more
specific description of the role.

* Works to transform large stores of data into business value by discovering, interpreting, and communicating data trends.
* Collects and pre-processes data for analysis.
* Applies data mining, statistical analysis, and modeling techniques to isolate and visualize patterns.
* Presents results in a readily consumable manner for non-technical personnel.
* Resolves technical issues and creates documentation as needed.

### Knowledge, Skills, Ability

* Exceptional proficiency in statistical analysis, quantitative analytics, and optimization algorithms.
* Excellent fluency with relational databases and SQL.
* Expertise in R in addition to at least one of the following: Python, Java, C++.
* Comprehensive knowledge of Big Data technologies such as Hadoop, Map Reduce, and Hive.
* Superior technical knowledge as well as demonstrated problem-solving, analytical, and troubleshooting abilities.
* Expertise in several of the following: data visualization, statistics, data mining, modeling, programming, big data.
* Consummate knowledge of Rackspace internal operations, structure, and systems with an aptitude for driving improvement in these areas.
* Excellent knowledge of product development life cycle and the ability to develop new test methodologies.
* Strategic knowledge of the hosting industry, an understanding of how related technologies are used in hosting and cloud, and an ability to determine where technologies fit within Rackspace.
* Outstanding presentation skills.
* Ability to develop training curriculum for a given domain and train others on how to teach the curriculum.

### Job Complexity

* Establishes and drives new and innovative solutions.
* Provides strategic technical leadership.
* Oversees management of multiple projects.
* Takes responsibility for technical readiness of cross functional projects of the highest complexity.
* Oversees data collection, statistical analysis, visualization, and modeling.
* Works at a high level with other engineering teams to ensure project continuity and quality.
* Develops new test methodologies.
* Fosters positive working relationships with internal/external stakeholder and partner groups, including executive leaders and vendors.
* Acts as primary point of contact for owned projects.
* Creates industry-level technical documentation.
* Leads presentations.
* Develops curriculum for technical training and trains others on teaching the material.
* Mentors lower level team members.

### Supervision

* Operates under minimal supervision.

### Experience and Education

* Bachelorâ€™s degree in Mathematics, Statistics, Computer Science, or related field required.  Advanced degree preferred.
* 7+ years of work experience in hands-on data analysis and programming with some management experience.

### Physical Demands

* General office environment.
* May require long periods sitting and viewing a computer monitor.
* Moderate levels of stress may occur at times.
* No special physical demands required.

## Ops Fabric Data Scientist Focus

### Background

Rackspace is a hosting company based in San Antonio, Texas
that prides itself in providing industry-leading customer support
and hosting value for those that are making the logical move to managed computing.
We are growing rapidly due to our past successes (delighted customers), business model
and excellent customer support, and are looking for highly-motivated, competent individuals
that can help propel us to the next level.

### Profile

More specifically, the Rackspace Private Cloud team is looking for an experienced Data Scientist
who's adaptable and can help us understand and solve our business problems, and for someone who's
a great communicator that can work with our team and customers and help ensure that everyone
understands the data, and the insights we're deriving from it.

### Position Summary

As a member of the Rackspace Private Cloud (RPC) Operational
Fabric team, you'll work with software developers, SREs, and stakeholders to help
us transform RPC into a data-driven organization.  You'll do this by helping our team
understand the existing data, asking the right questions, gathering the right
information, and building models and self-service reports to help our business
leaders make sound data-driven decisions about how to scale and operate our
organization.

### Responsibilities

- Collaborate with data experts to identify the most valuable KPI data and reports
that would enable business stakeholders to make the most informed decisions.
- Collaborate with data experts to identify the most valuable metrics data and reports
that would enable operations to drive towards the goal of zero downtime.
- Develop a deep understanding of the business and its most important data.
- Collaborate with Data Engineers on Data Pipeline design/development to ensure data recency,
breadth and accuracy.
- Help facilitate and standardize data quality across data stores.
- Facilitate mentoring and sharing of Data Science / Machine Learning techniques and
solutions to local teams as well as the Data Science Community in general.
- Attend team meetings, communicate often regarding status and be the goto person on the team
for Data-related issues.

### About Us

- **Team Size**: Currently 8 senior developers/engineers and a technical manager.
- **Hours**: We have flexible working hours and aim for a median of 35-40 hours a week.
- **Location**: US/UK work from home with offices in US/UK (most states supported).
- **Travel**: About once or twice a year for a conference or team gathering.

### Knowledge, Skills, Ability

It's important to go into a job understanding what you'll be working on, and what
skills you need to be successful.  We've outlined some requirements below to
help you get a feel for the job and what you'll be doing day-to-day.  At a high
level, we're looking for folks who can jump right into the middle of our data,
sit down with customers, and start understanding how to build models and create
reports in order to help our team make more data-driven management decisions.

#### Required

These are some attributes that we think a successful candidate will need in order
to be effective in the role.  We know people have different strengths and
weaknesses, but you should have some experience with all of these, and be ready
to use them on a daily basis.

  - Strong experience in machine learning techniques (unsupervised, supervised, reinforcement,
    demonstration, etc.) and optimization algorithms that include statistical analysis techniques
    such as Grouping, Clustering, Linear Regression, Stochastic Gradient Descent, Principal
    Component Analysis as well as Recurrent and Convolutional Neural Networks.
  - Familiarity with Basic SQL.
  - Proficiency with at least one programming language like Python or R, to a
    level where you are comfortable writing a complete stand-alone applications
    for Exploratory Data Analysis (EDA) to implementing full models.
  - Familiarity with data architecture, specifically data pipelines and data warehouses/lakes.
  - Familiarity with big data tools like Spark, Hadoop, Kafka, Cassandra or their cloud equivalents.

#### Additional

In addition to the key skills listed above, here are some other skills that
you'll likely be using on a regular basis.  We don't expect everyone to have all
of these skills, but exceptional candidates will have experience with, or be
excited to learn, most of these:

  - Understanding of SQL and no-SQL databases and the ability to read, write and
    optimize complex queries.
  - Knowledge of business analytics, and comfort working with stakeholders using
    common business terminology.
  - Familiarity with interactive notebooks to communicate your work such as iPython,
    Jupyter or Google DataLab.
  - Familiarity and experience with deep learning tools and techniques using tools such as
    Keras, TensorFlow, Theano, etc.
  - Familiarity and experience with Natural Language Processing (NLP) and text data mining.
  - Familiarity with data visualization, including proficiency with at least one
    data visualization framework such as Tableau, Looker, Canvas, Processing or D3.
  - Experience working on software development projects and with common Software Development
    Lifecycle patterns such as Agile/Scrum/Kanban.

### Supervision

We're a helpful and supportive group, and we're not going to leave you without a
clue of where to go or what to do.  That said, we're looking for senior level
individuals who can demonstrate a high degree of autonomy and provide
self-direction.  After all, you'll be the domain expert in your area.

  - Operate with little or no direct Supervision.
  - Work with stakeholders and customers inside of Rackspace to set priorities
    and goals.
  - Self-organize with other team members to deliver customer value.

### Experience and Education

There are a lot of ways to get experience.  Hands on work and education are both
great ways to learn what you need to do for the job.  We're looking for someone who
has an advanced degree in Statistics, Physics, Mathematics, Computer Science
or another technology-related field, as well as 7+ years of hands-on experience working
with statistical, data analysis and Machine Learning.

## Additional Info

### Contact

Please email your resume/github/linkedin (your choice!) to [Jesse J.
Cook](jesse.cook@rackspace.com). No agencies or recruiters please.

### Equal Employment Opportunity Policy

Rackspace is committed to offering equal employment opportunity without regard
to age, color, disability, gender, gender identity, genetic information,
marital status, military status, national origin, race, religion, sexual
orientation, veteran status, or any other legally protected characteristic.
